{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the correlation between the time of the year and the human activity? \n",
    "    - By Year, indexing the month of the year\n",
    "    - By Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pymysql\n",
    "#from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2016\n",
    "#year=int(input('Enter the year: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisition():\n",
    "    df=pd.read_csv('/Users/jidekickpush/Documents/GitHub/0323_2020DATAPAR/Labs/module_1/Pipelines-Project/Data/GSAF5.csv', encoding ='cp1252')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    #From the table overview, we can see the following statements:\n",
    "    #* columns 'unnamed: 22' and 'unnamed: 23' are not referenced in the description of the dataset and doesn't contain any (relevant) information.\n",
    "    #* columns 'Case Number.1' and 'Case Number.2'are duplicates of 'Case Number'\n",
    "    #* columns 'date' cannot be nomalised cause of the differents syntaxes but the information can be extract from column 'Case Number'\n",
    "    #=> Proceed to drop those columns\n",
    "    null_cols = df.isnull().sum()\n",
    "    null_cols\n",
    "    null_cols[null_cols > 0]\n",
    "    df=df.drop(['Unnamed: 22','Unnamed: 23','Case Number.1','Case Number.2','Date'], axis=1)\n",
    "    \n",
    "    # Some names of the columns aren't clean or clear enough. Below the list of columns renamed\n",
    "    #* Sex: remove a blank space at the end.\n",
    "    df.rename(columns={'Sex ':'Sex', 'Country':'Place'}, inplace = True)\n",
    "    \n",
    "    \n",
    "    #Among the total 5900 events registered, only 137 happened before 1700.\n",
    "    #To evaluate only statistically relevant data, events registered before 1700 will not be considered\n",
    "    df=df[df['Year']>1700]\n",
    "    \n",
    "    #Let's fix 'Sex' column: Typo found on 2 entrances.\n",
    "    #For 'Place': We've reduced the list of countries from the original set of 196 categories, to 174.\n",
    "    #=>For that purpose we have used both regular expressions and manual replacement.\n",
    "    df.replace({'Sex':{'M ':'M'}}, inplace=True)\n",
    "    \n",
    "    #remove end ?\n",
    "    #remove start/end blank spaces\n",
    "    #remove 2nd country after /\n",
    "    #df.columnname.str.replace('word','newword')\n",
    "    df.replace(regex={\n",
    "    r'\\?':'', \n",
    "    r'\\s\\/\\s[A-Z\\s]+': '', \n",
    "    r'\\s$':'', r'^\\s':''\n",
    "    }, inplace=True)\n",
    "    \n",
    "    #On 'Place' column, manually fixed some duplicates\n",
    "    df.replace({'Place': { 'UNITED ARAB EMIRATES (UAE)':'UNITED ARAB EMIRATES', \n",
    "    'Fiji':'FIJI', 'ST. MAARTIN':'ST. MARTIN', \n",
    "    'Seychelles':'SEYCHELLES', \n",
    "    'Sierra Leone':'SIERRA LEONE', \n",
    "    'St Helena': 'ST HELENA', \n",
    "    'ENGLAND': 'UNITED KINGDOM', \n",
    "    'SCOTLAND': 'UNITED KINGDOM'}\n",
    "    }, inplace=True)\n",
    "    \n",
    "    #Normalizing column Activity\n",
    "    #Reduce from the original 1418 unique values on Activity to 5: 'Surfing', 'Swimming', 'Fishing', 'Diving' & 'Others'.\n",
    "    df.rename(columns={'Activity':'unActivity'}, inplace=True)\n",
    "    df_activity = df['unActivity']\n",
    "    activity = []\n",
    "    for a in df_activity:\n",
    "        if re.search(r'Surf[\\w\\s\\,]+|surf[\\w\\s\\,]+|[\\w\\s\\,]+surf[\\w\\s\\,]+', str(a)):\n",
    "            a = 'Surfing'\n",
    "        elif re.search(r'Fish[\\w\\s\\,]+|fish[\\w\\s\\,]+|[\\w\\s\\,]+fish[\\w\\s\\,]+', str(a)):\n",
    "            a = 'Fishing'\n",
    "        elif re.search(r'Spear[\\w\\s\\,]+|spear[\\w\\s\\,]+|[\\w\\s\\,]+spear[\\w\\s\\,]+', str(a)):\n",
    "            a = 'Fishing'\n",
    "        elif re.search(r'Swim[\\w\\s\\,]+|swim[\\w\\s\\,]+|[\\w\\s\\,]+swim[\\w\\s\\,]+', str(a)):\n",
    "            a = 'Swimming'\n",
    "        elif re.search(r'Div[\\w\\s\\,]+|div[\\w\\s\\,]+|[\\w\\s\\,]+div[\\w\\s\\,]+', str(a)):\n",
    "            a = 'Diving'\n",
    "        else: a = 'Others'\n",
    "        activity.append(a)\n",
    "    df['Activity'] = activity\n",
    "    df = df.drop(['unActivity'], axis=1)\n",
    "    \n",
    "    \n",
    "    #Create a new column for dates, getting the information from the column 'Case Number'\n",
    "    df['Date']=df['Case Number']\n",
    "    df['Date'].replace(regex = {r'.[A-Za-z]$':''}, inplace = True)\n",
    "    \n",
    "    #Create a new column for the month, extracting it from the 'Case Number' column\n",
    "    #* check if percentage of unrelevant dates : month missing in the data\n",
    "    #=> drop the rows without specified month\n",
    "    df['Month']=[m[5:7] for m in df['Case Number']]\n",
    "    \n",
    "    #Percentage of month not specified in the df is less than 10%, we decided to do not keep them:\n",
    "    # Get 'Months' of indexes for which column month has value 00\n",
    "    indexNames = df[ df['Month'] == '00' ].index\n",
    "    # Delete these row indexes from dataFrame\n",
    "    df.drop(indexNames , inplace=True)\n",
    "    \n",
    "    #Normalizing the hour, keeping only the values that correspond to a 24h value\n",
    "    ###df['Time'] = df['Time'].replace(regex = {r'\\s[\\w\\-\\d\\/\\()]+|\\-[\\w\\-\\d\\/]+|j$|^\\>|^\\<':'', r'h':':'})\n",
    "    ###hour = []\n",
    "    #time = df['Time']\n",
    "    #for h in time:\n",
    "     #   if re.search(r'\\d{2}\\:\\d{2}', str(h)) == None:\n",
    "     #       h = 'Unknown'\n",
    "    #    hour.append(h)\n",
    "    #df['Hour'] = hour\n",
    "    \n",
    "    #Change column types\n",
    "    #Change the column Fatal (Y/N) to a boolean, normalizing all the entries to True or False.\n",
    "    #The few unknown values have been trated as non fatal.\n",
    "    df.rename(columns={ 'Fatal (Y/N)' : 'Fatal'}, inplace=True)\n",
    "    df = df.replace({'Fatal': { 'N' : '0', 'Y' : '1', 'n' : '0', 'y' : '1', 'UNKNOWN' : '0', 'F' : '0', '#VALUE!' : '0'}})\n",
    "    df['Fatal'].astype(bool)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_year(df):\n",
    "    global year\n",
    "    filtered=df[df.Year==year]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_seasonality_attacks(df)\n",
    "    #Binning the data by season on a new column\n",
    "    season_labels=['Winter','Spring','Summer','Fall']\n",
    "    cutoffs= [1,4,7,10,12]\n",
    "    bins = pd.cut(df['Month'], cutoffs, labels=season_labels)\n",
    "    seasonality = seasonality.round({'Ratio' : 2})\n",
    "    df['Season']=bins\n",
    "    \n",
    "    #Ratio of attacks per person\n",
    "    seasonality = df.pivot_table(index=['Season'], values=['Date'], aggfunc= len,fill_value=0)\n",
    "    seasonality = seasonality.rename(columns= {'Date':'Count'})\n",
    "    seasonality['Ratio'] = seasonality['Count'] * 100 / seasonality['Count'].sum()\n",
    "    seasonality = seasonality.round({'Ratio':2})\n",
    "    #display(seasonality)\n",
    "    return seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_seasonality_per_activity(df):\n",
    "    df.groupby('Activity').Season.value_counts(normalize=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_table(df):\n",
    "    #Filtered TableÂ¶\n",
    "    #10 columns with categorized data selected to further analysis.\n",
    "    #Excluded from this final table the columns with unique values.\n",
    "    filtered_table = df[['Date', 'Year', 'Month', 'Hour', 'Place', 'Area','Location', 'Activity', 'Sex', 'Fatal']]\n",
    "    filtered_table.to_csv(\"/Users/jidekickpush/Documents/GitHub/0323_2020DATAPAR/Labs/module_1/Pipelines-Project/output/cleaned_df_GSAF5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'pd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8d497eabca4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macquisition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_cleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata_filtered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_by_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'pd'"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    data_raw=acquisition()\n",
    "    data_cleaned=data_cleaning(data_raw)\n",
    "    data_filtered=filter_by_year(data_cleaned)\n",
    "    data_seasonality = display_seasonality_attacks(data_filtered)\n",
    "    display(data_seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
